## Overview

This project is a simple artificial neural network implemented from scratch in Java without using any machine learning libraries. The goal of the project is to understand the internal workings of neural networks, including forward propagation, backpropagation, weight updates, and matrix operations.

## Motivation

The project was built to strengthen my understanding of how neural networks function at a low level, rather than relying on high-level frameworks. It focuses on learning the math, data flow, and architecture behind neural networks. I came across an article online that implemented a similar project in Python, but I wanted to do it in Java to understand what is really going on.

## Features

- Fully connected feedforward neural network

- Custom implementation of neurons, layers, weights, and biases

- Forward propagation and backpropagation

- Gradient-based weight and bias updates

- Configurable network architecture (input, hidden, output layers)

- No external ML libraries used

## Technologies Used

- Java

- Basic linear algebra and matrix operations

## What I Learned

- Neural network architecture and data flow

- Forward and backward propagation mechanics

- Gradient descent and loss minimization

- Handling dimensionality and matrix operations

## Project Structure

- Main.java Entire project 

## How to Run

- Clone the repository

- Compile the Java files

- Run the main class to train and test the network

- Make sure to reference the MNIST dataset to your local machine be yourself. 

Author

Avash
